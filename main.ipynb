{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "from scipy.stats import t, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variáveis globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_RODADAS = 3300\n",
    "N_RODADAS = 10\n",
    "\n",
    "N_AMOSTRAS = 1000\n",
    "\n",
    "MU = 1.0\n",
    "RHOS = [0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "\n",
    "CHEGADA = 0\n",
    "FIM_DO_SERVICO_1 = 1\n",
    "FIM_DO_SERVICO_2 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcionamento geral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando VAs exponenciais\n",
    "Resultado mostrado na aula 5, slide 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_exponencial(rho):\n",
    "\n",
    "    # Gera VA uniforme no intervalo [0.0, 1.0)\n",
    "    u0 = random.random()\n",
    "\n",
    "    # Pega amostra da exponencial\n",
    "    x0 = -math.log(u0)/ rho\n",
    "\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando números aleatórios\n",
    "Os seeds em Python são definidos por meio da função random.seed(int) e fixamos um seed antes cada simulação para garantir a reprodutibilidade dos resultados. Para garantir a independência dos seeds, rodamos o algoritmo com alguns seeds diferentes ao longo do trabalho.\n",
    "\n",
    "Além disso também fizemos alguns testes para mostrar que não há sobreposição entre os intervalos gerados pelos seeds.\n",
    "\n",
    "Mesmo usando seeds próximas (0 e 1, por exemplo) não encontramos sobreposição das sequências de valores nem uma correlação significativa. Acreditamos que isso se deve ao fato de o Python utilizar o algoritmo do Mersenne Twister para gerar números pseudoaleatórios (https://en.wikipedia.org/wiki/Mersenne_Twister)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_amostras(rho, seed):\n",
    "\n",
    "    rodadas = []\n",
    "\n",
    "    random.seed(seed)\n",
    "    \n",
    "    for _ in range(N_RODADAS):\n",
    "        amostras = []\n",
    "\n",
    "        for _ in range(N_AMOSTRAS):\n",
    "            amostras.append(gera_exponencial(rho))\n",
    "        \n",
    "        rodadas.append(amostras)\n",
    "    \n",
    "    # Lista de rodadas com números aleatórios gerados pela amostra exponencial\n",
    "    return rodadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro geramos 2 vetores com váriaveis exponenciais com mesma taxa, cada um a partir de uma seed diferente. E depois verificamos se existem valores em comuns nesses vetores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_gera_amostras(rodadas_A, rodadas_B):\n",
    "\n",
    "    tamanho_lista_rodadas = len(rodadas_A)\n",
    "\n",
    "    for rodada_A in range(tamanho_lista_rodadas - 1):\n",
    "        lista_rodada = rodadas_A[rodada_A]\n",
    "\n",
    "        for rodada_B in range(tamanho_lista_rodadas):\n",
    "            verifica_lista = rodadas_B[rodada_B]\n",
    "\n",
    "            verificacao = list(set(lista_rodada).intersection(verifica_lista))\n",
    "            if(len(verificacao) > 0):\n",
    "                return \"Foram encontrados valores iguais\"\n",
    "            \n",
    "    return \"Não há valores iguais entre as duas rodadas\"       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Não há valores iguais entre as duas rodadas'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rodadas_A = gera_amostras(0.3, 0)\n",
    "rodadas_B = gera_amostras(0.3, 1)\n",
    "\n",
    "teste_gera_amostras(rodadas_A, rodadas_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No outro teste geramos 2 vetores também e verificamos o indíce de correlação (Pearson) entre eles.\n",
    "\n",
    "- +1: correlação positiva completa\n",
    "- +0.8: correlação positiva forte\n",
    "- +0.6: correlação positiva moderada\n",
    "- 0: nenhuma correlação\n",
    "- -0.6: correlação negativa moderada\n",
    "- -0.8: correlação negativa forte\n",
    "- -1: correlação negativa completa\n",
    "\n",
    "Referência: https://stackabuse.com/calculating-pearson-correlation-coefficient-in-python-with-numpy/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_pearson_gera_amostras(seed_1, seed_2):\n",
    "\n",
    "    rodadas = []\n",
    "    amostras_1 = []\n",
    "    amostras_2 = []\n",
    "\n",
    "    random.seed(seed_1)\n",
    "    for _ in range(N_AMOSTRAS):\n",
    "        amostras_1.append(random.random())\n",
    "    rodadas.append(amostras_1)\n",
    "\n",
    "    random.seed(seed_2)\n",
    "    for _ in range(N_AMOSTRAS):\n",
    "        amostras_2.append(random.random())\n",
    "    rodadas.append(amostras_2)\n",
    "\n",
    "    x_pearson = pd.Series(rodadas[0])\n",
    "    y_pearson = pd.Series(rodadas[1])\n",
    "\n",
    "    resultado = x_pearson.corr(y_pearson)\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015488472306667765"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_pearson_gera_amostras(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evento:\n",
    "\n",
    "    def __init__(self, tipo_evento, instante_t, tempo_execucao, id_cliente):\n",
    "        self.tipo_evento = tipo_evento\n",
    "        self.instante_t = instante_t #tempo em que o evento foi criado + tempo até ser executado\n",
    "        self.tempo_execucao = tempo_execucao #tempo até ser executado\n",
    "        self.id_cliente = id_cliente\n",
    "\n",
    "    # Define como a classe é impressa\n",
    "    def __repr__(self):\n",
    "        if(self.tipo_evento == CHEGADA):\n",
    "            escreve_string = \"CHEGADA\"\n",
    "        elif self.tipo_evento == FIM_DO_SERVICO_1:\n",
    "            escreve_string = \"FIM DO SERVIÇO 1\"\n",
    "        else:\n",
    "            escreve_string = \"FIM DO SERVIÇO 2\"\n",
    "\n",
    "        return f\"Tipo de evento: {escreve_string}\\n Instante: {self.instante_t}\\n ID Cliente: {self.id_cliente}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tipo de evento: CHEGADA\n",
       " Instante: 0.1\n",
       " ID Cliente: 0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evento = Evento(CHEGADA, 0.1, 0, 0)\n",
    "evento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cliente:\n",
    "\n",
    "    def __init__(self, chegada_evento, cor):\n",
    "        self.id = chegada_evento.id_cliente\n",
    "        self.tempo_chegada = chegada_evento.instante_t\n",
    "        self.tempo_execucao_1 = 0.0\n",
    "        self.tempo_execucao_2 = 0.0\n",
    "        self.tempo_espera_1 = 0.0\n",
    "        self.tempo_espera_2 = 0.0\n",
    "        self.cor = cor\n",
    "\n",
    "    # Define como a classe é impressa\n",
    "    def __repr__(self):\n",
    "        return f\"\"\"ID: {self.id}\n",
    "        Tempo de chegada: {self.tempo_chegada}\n",
    "        Tempo de espera na fila 1: {self.tempo_espera_1}\n",
    "        Tempo de execucao no servico 1: {self.tempo_execucao_1}\n",
    "        Tempo de espera na fila 2: {self.tempo_espera_2}\n",
    "        Tempo de execucao no servico 2: {self.tempo_execucao_2}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_cliente(evento, cor):\n",
    "    novo_cliente = Cliente(evento, cor)\n",
    "    return novo_cliente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID: 0\n",
       "        Tempo de chegada: 0.1\n",
       "        Tempo de espera na fila 1: 0.0\n",
       "        Tempo de execucao no servico 1: 0.0\n",
       "        Tempo de espera na fila 2: 0.0\n",
       "        Tempo de execucao no servico 2: 0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = \"%06x\" % random.randint(0, 0xFFFFFF)\n",
    "cliente = cria_cliente(evento, cor)\n",
    "cliente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando chegadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_chegadas(instante_t, distribuicao_chegada, id_cliente):\n",
    "    chegada = distribuicao_chegada()\n",
    "    chegada = Evento(CHEGADA, instante_t + chegada, chegada, id_cliente)\n",
    "    return chegada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tipo de evento: CHEGADA\n",
       " Instante: 7.3608989036521555\n",
       " ID Cliente: 0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chegada = gera_chegadas(1, partial(gera_exponencial, 0.3), 0)\n",
    "chegada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando fins de serviço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_fim_servico(instante_t, distribuicao_servico, id_cliente, tipo):\n",
    "    servico = distribuicao_servico()\n",
    "    fim_servico = Evento(tipo, instante_t + servico, servico, id_cliente)\n",
    "    return fim_servico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tipo de evento: FIM DO SERVIÇO 1\n",
       " Instante: 14.537812031853182\n",
       " ID Cliente: 1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fim_servico = gera_fim_servico(10, partial(gera_exponencial, 0.3), 1, FIM_DO_SERVICO_1)\n",
    "fim_servico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervalos de confiança"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Student\n",
    "Resultado apresentado na aula 7, slides 4 e 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_student(media, variancia, amostras):\n",
    "    t_student_percentil = t(df = amostras - 1).ppf((0.025, 0.975))[1]\n",
    "\n",
    "    # Verifica se a média e variância têm valores nulos (ou próximos disso)\n",
    "    if(math.isclose(media, 0, abs_tol = 1e-9)):\n",
    "        media = 0\n",
    "\n",
    "    if(math.isclose(variancia, 0, abs_tol = 1e-9)):\n",
    "        variancia = 0\n",
    "\n",
    "    # Se a média e variância forem nulas\n",
    "    if(not(media or variancia)):\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    desvio_padrao = math.sqrt(variancia)\n",
    "\n",
    "    # Metade do intervalo\n",
    "    metade = t_student_percentil * (desvio_padrao/ math.sqrt(amostras))\n",
    "\n",
    "    # Limite superior do intervalo\n",
    "    limite_superior = media + metade\n",
    "\n",
    "    # Limite inferior do intervalo\n",
    "    limite_inferior = media - metade\n",
    "\n",
    "    # Precisão do intervalo\n",
    "    precisao = metade/ media\n",
    "\n",
    "    return limite_superior, limite_inferior, precisao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chi-Quadrado\n",
    "Resultado apresentado na aula 7, slides 12 ao 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_quadrado(variancia, amostras):\n",
    "    chi2_0025_percentil, chi2_0975_percentil = chi2(df = amostras - 1).ppf((0.025, 0.975))\n",
    "\n",
    "    if(variancia == 0.0):\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    else:\n",
    "        limite_superior = (amostras) * variancia/ chi2_0975_percentil\n",
    "        limite_inferior = (amostras) * variancia/ chi2_0025_percentil\n",
    "\n",
    "        # Enunciado pede que seja aproximadamente 0.05\n",
    "        precisao = (chi2_0975_percentil - chi2_0025_percentil)/ (chi2_0975_percentil + chi2_0025_percentil)\n",
    "\n",
    "        return limite_superior, limite_inferior, precisao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimadores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa classe permite o cálculo iterativo da média e da variância de uma variável, recebendo uma amostra de cada vez.\n",
    "Esse resultado foi apresentado na aula 7, slide 19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimador:\n",
    "\n",
    "    def __init__(self, debug=False):\n",
    "        self.soma_amostras = 0.0\n",
    "        self.quadrado_soma_amostras = 0.0\n",
    "        self.numero_amostras = 0\n",
    "        self.debug = debug\n",
    "        \n",
    "        self.medias = []\n",
    "        self.variancias = []\n",
    "        self.pesos = []\n",
    "\n",
    "    def adiciona_amostra(self, amostra, peso=1):\n",
    "        peso = 1\n",
    "        self.soma_amostras += amostra*peso\n",
    "        self.quadrado_soma_amostras += ((amostra) ** 2)\n",
    "        self.numero_amostras += peso\n",
    "        \n",
    "        #salvar resultados intermediários para plots futuros\n",
    "        if self.debug and self.numero_amostras > 1:\n",
    "            self.pesos.append(self.numero_amostras)\n",
    "            self.medias.append(self.media())\n",
    "            self.variancias.append(self.variancia())\n",
    "\n",
    "    def media(self):\n",
    "        return self.soma_amostras/ self.numero_amostras\n",
    "\n",
    "    def variancia(self):\n",
    "        termo_auxiliar_1 = self.quadrado_soma_amostras/ (self.numero_amostras - 1)\n",
    "        termo_auxiliar_2 = (self.soma_amostras ** 2)/ (self.numero_amostras * (self.numero_amostras - 1))\n",
    "        return termo_auxiliar_1 - termo_auxiliar_2\n",
    "\n",
    "    def t_student(self):\n",
    "        return t_student(self.media(), self.variancia(), self.numero_amostras)\n",
    "\n",
    "    def variancia_chi_quadrado(self):\n",
    "        return chi_quadrado(self.variancia(), self.numero_amostras)\n",
    "\n",
    "    def chi_quadrado(self):\n",
    "        return chi_quadrado(self.media(), self.numero_amostras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042140685846143874"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimador = Estimador(debug=True)\n",
    "estimador.adiciona_amostra(10)\n",
    "estimador.adiciona_amostra(11)\n",
    "estimador.adiciona_amostra(10)\n",
    "estimador.adiciona_amostra(10)\n",
    "estimador.adiciona_amostra(10)\n",
    "estimador.adiciona_amostra(10)\n",
    "estimador.t_student()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código base para simular o sistema com prints depurativos para acompanhar chegadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo 4.502981437579455\n",
      "Chegada ID: 0\n",
      "        Tempo de chegada: 4.502981437579455\n",
      "        Tempo de espera na fila 1: 0.0\n",
      "        Tempo de execucao no servico 1: 0.0\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 1\n",
      " Instante: 4.88265904292863\n",
      " ID Cliente: 0, Tipo de evento: CHEGADA\n",
      " Instante: 5.762847702789278\n",
      " ID Cliente: 1]\n",
      "\n",
      "Tempo 4.88265904292863\n",
      "Saída 1 ID: 0\n",
      "        Tempo de chegada: 4.502981437579455\n",
      "        Tempo de espera na fila 1: -1.6653345369377348e-16\n",
      "        Tempo de execucao no servico 1: 0.37967760534917544\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 2\n",
      " Instante: 5.0459592641554\n",
      " ID Cliente: 0, Tipo de evento: CHEGADA\n",
      " Instante: 5.762847702789278\n",
      " ID Cliente: 1]\n",
      "\n",
      "Tempo 5.0459592641554\n",
      "Saída 2 ID: 0\n",
      "        Tempo de chegada: 4.502981437579455\n",
      "        Tempo de espera na fila 1: -1.6653345369377348e-16\n",
      "        Tempo de execucao no servico 1: 0.37967760534917544\n",
      "        Tempo de espera na fila 2: -8.326672684688674e-17\n",
      "        Tempo de execucao no servico 2: 0.16330022122676988\n",
      "[Tipo de evento: CHEGADA\n",
      " Instante: 5.762847702789278\n",
      " ID Cliente: 1]\n",
      "\n",
      "Tempo 5.762847702789278\n",
      "Chegada ID: 1\n",
      "        Tempo de chegada: 5.762847702789278\n",
      "        Tempo de espera na fila 1: 0.0\n",
      "        Tempo de execucao no servico 1: 0.0\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 1\n",
      " Instante: 7.2300978828248885\n",
      " ID Cliente: 1, Tipo de evento: CHEGADA\n",
      " Instante: 11.374489843021717\n",
      " ID Cliente: 2]\n",
      "\n",
      "Tempo 7.2300978828248885\n",
      "Saída 1 ID: 1\n",
      "        Tempo de chegada: 5.762847702789278\n",
      "        Tempo de espera na fila 1: 2.220446049250313e-16\n",
      "        Tempo de execucao no servico 1: 1.4672501800356101\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 2\n",
      " Instante: 9.146333287642788\n",
      " ID Cliente: 1, Tipo de evento: CHEGADA\n",
      " Instante: 11.374489843021717\n",
      " ID Cliente: 2]\n",
      "\n",
      "Tempo 9.146333287642788\n",
      "Saída 2 ID: 1\n",
      "        Tempo de chegada: 5.762847702789278\n",
      "        Tempo de espera na fila 1: 2.220446049250313e-16\n",
      "        Tempo de execucao no servico 1: 1.4672501800356101\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 1.9162354048178996\n",
      "[Tipo de evento: CHEGADA\n",
      " Instante: 11.374489843021717\n",
      " ID Cliente: 2]\n",
      "\n",
      "Tempo 11.374489843021717\n",
      "Chegada ID: 2\n",
      "        Tempo de chegada: 11.374489843021717\n",
      "        Tempo de espera na fila 1: 0.0\n",
      "        Tempo de execucao no servico 1: 0.0\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 1\n",
      " Instante: 11.683703938303086\n",
      " ID Cliente: 2, Tipo de evento: CHEGADA\n",
      " Instante: 16.344259779021087\n",
      " ID Cliente: 3]\n",
      "\n",
      "Tempo 11.683703938303086\n",
      "Saída 1 ID: 2\n",
      "        Tempo de chegada: 11.374489843021717\n",
      "        Tempo de espera na fila 1: 4.440892098500626e-16\n",
      "        Tempo de execucao no servico 1: 0.3092140952813689\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 2\n",
      " Instante: 13.722287471316251\n",
      " ID Cliente: 2, Tipo de evento: CHEGADA\n",
      " Instante: 16.344259779021087\n",
      " ID Cliente: 3]\n",
      "\n",
      "Tempo 13.722287471316251\n",
      "Saída 2 ID: 2\n",
      "        Tempo de chegada: 11.374489843021717\n",
      "        Tempo de espera na fila 1: 4.440892098500626e-16\n",
      "        Tempo de execucao no servico 1: 0.3092140952813689\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 2.038583533013165\n",
      "[Tipo de evento: CHEGADA\n",
      " Instante: 16.344259779021087\n",
      " ID Cliente: 3]\n",
      "\n",
      "Tempo 16.344259779021087\n",
      "Chegada ID: 3\n",
      "        Tempo de chegada: 16.344259779021087\n",
      "        Tempo de espera na fila 1: 0.0\n",
      "        Tempo de execucao no servico 1: 0.0\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 1\n",
      " Instante: 17.886471236869582\n",
      " ID Cliente: 3, Tipo de evento: CHEGADA\n",
      " Instante: 18.45226204682543\n",
      " ID Cliente: 4]\n",
      "\n",
      "Tempo 17.886471236869582\n",
      "Saída 1 ID: 3\n",
      "        Tempo de chegada: 16.344259779021087\n",
      "        Tempo de espera na fila 1: 2.220446049250313e-16\n",
      "        Tempo de execucao no servico 1: 1.542211457848495\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: CHEGADA\n",
      " Instante: 18.45226204682543\n",
      " ID Cliente: 4, Tipo de evento: FIM DO SERVIÇO 2\n",
      " Instante: 19.10841538352262\n",
      " ID Cliente: 3]\n",
      "\n",
      "Tempo 18.45226204682543\n",
      "Chegada ID: 4\n",
      "        Tempo de chegada: 18.45226204682543\n",
      "        Tempo de espera na fila 1: 0.0\n",
      "        Tempo de execucao no servico 1: 0.0\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 1\n",
      " Instante: 18.629409201355013\n",
      " ID Cliente: 4, Tipo de evento: FIM DO SERVIÇO 2\n",
      " Instante: 19.2855625380522\n",
      " ID Cliente: 3, Tipo de evento: CHEGADA\n",
      " Instante: 21.253267463386024\n",
      " ID Cliente: 5]\n",
      "\n",
      "Tempo 18.629409201355013\n",
      "Saída 1 ID: 4\n",
      "        Tempo de chegada: 18.45226204682543\n",
      "        Tempo de espera na fila 1: 1.4432899320127035e-15\n",
      "        Tempo de execucao no servico 1: 0.1771471545295803\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 2\n",
      " Instante: 19.2855625380522\n",
      " ID Cliente: 3, Tipo de evento: CHEGADA\n",
      " Instante: 21.253267463386024\n",
      " ID Cliente: 5]\n",
      "\n",
      "Tempo 19.2855625380522\n",
      "Saída 2 ID: 3\n",
      "        Tempo de chegada: 16.344259779021087\n",
      "        Tempo de espera na fila 1: 2.220446049250313e-16\n",
      "        Tempo de execucao no servico 1: 1.542211457848495\n",
      "        Tempo de espera na fila 2: 0.1771471545295802\n",
      "        Tempo de execucao no servico 2: 1.2219441466530385\n",
      "[Tipo de evento: FIM DO SERVIÇO 2\n",
      " Instante: 19.78248172629007\n",
      " ID Cliente: 4, Tipo de evento: CHEGADA\n",
      " Instante: 21.253267463386024\n",
      " ID Cliente: 5]\n",
      "\n",
      "Tempo 19.78248172629007\n",
      "Saída 2 ID: 4\n",
      "        Tempo de chegada: 18.45226204682543\n",
      "        Tempo de espera na fila 1: 1.4432899320127035e-15\n",
      "        Tempo de execucao no servico 1: 0.1771471545295803\n",
      "        Tempo de espera na fila 2: 0.6561533366971866\n",
      "        Tempo de execucao no servico 2: 0.4969191882378688\n",
      "[Tipo de evento: CHEGADA\n",
      " Instante: 21.253267463386024\n",
      " ID Cliente: 5]\n",
      "\n",
      "Tempo 21.253267463386024\n",
      "Chegada ID: 5\n",
      "        Tempo de chegada: 21.253267463386024\n",
      "        Tempo de espera na fila 1: 0.0\n",
      "        Tempo de execucao no servico 1: 0.0\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 1\n",
      " Instante: 22.541213160340863\n",
      " ID Cliente: 5, Tipo de evento: CHEGADA\n",
      " Instante: 35.38086775507348\n",
      " ID Cliente: 6]\n",
      "\n",
      "Tempo 22.541213160340863\n",
      "Saída 1 ID: 5\n",
      "        Tempo de chegada: 21.253267463386024\n",
      "        Tempo de espera na fila 1: 1.1102230246251565e-15\n",
      "        Tempo de execucao no servico 1: 1.2879456969548382\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 2\n",
      " Instante: 24.460508395775964\n",
      " ID Cliente: 5, Tipo de evento: CHEGADA\n",
      " Instante: 35.38086775507348\n",
      " ID Cliente: 6]\n",
      "\n",
      "Tempo 24.460508395775964\n",
      "Saída 2 ID: 5\n",
      "        Tempo de chegada: 21.253267463386024\n",
      "        Tempo de espera na fila 1: 1.1102230246251565e-15\n",
      "        Tempo de execucao no servico 1: 1.2879456969548382\n",
      "        Tempo de espera na fila 2: -4.440892098500626e-16\n",
      "        Tempo de execucao no servico 2: 1.9192952354351012\n",
      "[Tipo de evento: CHEGADA\n",
      " Instante: 35.38086775507348\n",
      " ID Cliente: 6]\n",
      "\n",
      "Tempo 35.38086775507348\n",
      "Chegada ID: 6\n",
      "        Tempo de chegada: 35.38086775507348\n",
      "        Tempo de espera na fila 1: 0.0\n",
      "        Tempo de execucao no servico 1: 0.0\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 1\n",
      " Instante: 35.5919103057116\n",
      " ID Cliente: 6, Tipo de evento: CHEGADA\n",
      " Instante: 35.84015594292348\n",
      " ID Cliente: 7]\n",
      "\n",
      "Tempo 35.5919103057116\n",
      "Saída 1 ID: 6\n",
      "        Tempo de chegada: 35.38086775507348\n",
      "        Tempo de espera na fila 1: 2.1371793224034263e-15\n",
      "        Tempo de execucao no servico 1: 0.21104255063811692\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 2\n",
      " Instante: 35.80752373217134\n",
      " ID Cliente: 6, Tipo de evento: CHEGADA\n",
      " Instante: 35.84015594292348\n",
      " ID Cliente: 7]\n",
      "\n",
      "Tempo 35.80752373217134\n",
      "Saída 2 ID: 6\n",
      "        Tempo de chegada: 35.38086775507348\n",
      "        Tempo de espera na fila 1: 2.1371793224034263e-15\n",
      "        Tempo de execucao no servico 1: 0.21104255063811692\n",
      "        Tempo de espera na fila 2: -2.0816681711721685e-15\n",
      "        Tempo de execucao no servico 2: 0.21561342645974188\n",
      "[Tipo de evento: CHEGADA\n",
      " Instante: 35.84015594292348\n",
      " ID Cliente: 7]\n",
      "\n",
      "Tempo 35.84015594292348\n",
      "Chegada ID: 7\n",
      "        Tempo de chegada: 35.84015594292348\n",
      "        Tempo de espera na fila 1: 0.0\n",
      "        Tempo de execucao no servico 1: 0.0\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 1\n",
      " Instante: 36.134862425139765\n",
      " ID Cliente: 7, Tipo de evento: CHEGADA\n",
      " Instante: 36.475883619056106\n",
      " ID Cliente: 8]\n",
      "\n",
      "Tempo 36.134862425139765\n",
      "Saída 1 ID: 7\n",
      "        Tempo de chegada: 35.84015594292348\n",
      "        Tempo de espera na fila 1: 2.1094237467877974e-15\n",
      "        Tempo de execucao no servico 1: 0.29470648221628226\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: FIM DO SERVIÇO 2\n",
      " Instante: 36.18686816610382\n",
      " ID Cliente: 7, Tipo de evento: CHEGADA\n",
      " Instante: 36.475883619056106\n",
      " ID Cliente: 8]\n",
      "\n",
      "Tempo 36.18686816610382\n",
      "Saída 2 ID: 7\n",
      "        Tempo de chegada: 35.84015594292348\n",
      "        Tempo de espera na fila 1: 2.1094237467877974e-15\n",
      "        Tempo de execucao no servico 1: 0.29470648221628226\n",
      "        Tempo de espera na fila 2: 2.7131075164277263e-15\n",
      "        Tempo de execucao no servico 2: 0.052005740964053034\n",
      "[Tipo de evento: CHEGADA\n",
      " Instante: 36.475883619056106\n",
      " ID Cliente: 8]\n",
      "\n",
      "Tempo 36.475883619056106\n",
      "Chegada ID: 8\n",
      "        Tempo de chegada: 36.475883619056106\n",
      "        Tempo de espera na fila 1: 0.0\n",
      "        Tempo de execucao no servico 1: 0.0\n",
      "        Tempo de espera na fila 2: 0.0\n",
      "        Tempo de execucao no servico 2: 0.0\n",
      "[Tipo de evento: CHEGADA\n",
      " Instante: 37.245753080331355\n",
      " ID Cliente: 9, Tipo de evento: FIM DO SERVIÇO 1\n",
      " Instante: 37.83569973768443\n",
      " ID Cliente: 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(13) #setando uma seed pra manter os testes iguais\n",
    "\n",
    "mu = MU\n",
    "lamb = RHOS[2]/2\n",
    "\n",
    "fila1 = []\n",
    "fila2 = []\n",
    "tempo = 0\n",
    "eventos = [ gera_chegadas(0, partial(gera_exponencial, lamb), 0) ] # começa populando com uma chegada\n",
    "\n",
    "i = 1\n",
    "while i < 10: #loop de eventos, chegada de 10 clientes\n",
    "    atual = eventos.pop(0)\n",
    "    tempo = atual.instante_t\n",
    "    print(\"Tempo\", tempo)\n",
    "    \n",
    "    if atual.tipo_evento == CHEGADA: #evento de chegada\n",
    "        fila1.append( cria_cliente(atual, cor) ) #adiciona o cliente chegado na fila\n",
    "        eventos.append(gera_chegadas(tempo, partial(gera_exponencial, lamb), i) ) #cria o próximo evento de chegada\n",
    "        print(\"Chegada\", fila1[-1])\n",
    "        \n",
    "        checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_1 for e in eventos])\n",
    "        if not checa_termino: #essa foi a primeira chegada (não tem pessoas na fila 1)\n",
    "            prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), atual.id_cliente, FIM_DO_SERVICO_1) \n",
    "            eventos.append( prox_fim_1 ) #adiciona o próximo evento de término 1\n",
    "            \n",
    "            if len(fila2) != 0: # fila 2 tem alguém sendo executado\n",
    "                prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "        i+= 1\n",
    "    \n",
    "    elif atual.tipo_evento == FIM_DO_SERVICO_1:\n",
    "        cliente = fila1.pop(0) #remove o primeiro da fila 1\n",
    "        fila2.append( cliente ) #coloca cliente na fila 2\n",
    "        \n",
    "        #atualiza tempos do cliente\n",
    "        cliente.tempo_execucao_1= atual.tempo_execucao\n",
    "        cliente.tempo_espera_1 = tempo - cliente.tempo_chegada - atual.tempo_execucao\n",
    "        \n",
    "        checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_2 for e in eventos])\n",
    "        if not checa_termino: #essa foi o primeiro termino (não tem pessoas na fila 2)\n",
    "            eventos.append( gera_fim_servico(tempo, partial(gera_exponencial, mu), cliente.id, FIM_DO_SERVICO_2) ) #adiciona o próximo evento de término 1\n",
    "        \n",
    "        if len(fila1) == 0: #se a fila 1 estiver vazia\n",
    "            pass\n",
    "        else: #se a fila 1 não estiver vazia\n",
    "            prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila1[0].id, FIM_DO_SERVICO_1)  #cria evento de término para o próximo da fila 1\n",
    "            eventos.append( prox_fim_1 ) \n",
    "            \n",
    "            prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "            prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "        \n",
    "        print(\"Saída 1\", cliente)\n",
    "        \n",
    "    elif atual.tipo_evento == FIM_DO_SERVICO_2:\n",
    "        cliente = fila2.pop(0)\n",
    "        \n",
    "        #atualiza tempos do cliente\n",
    "        cliente.tempo_execucao_2= atual.tempo_execucao\n",
    "        cliente.tempo_espera_2 = tempo - cliente.tempo_chegada - cliente.tempo_execucao_1 - cliente.tempo_espera_1 - atual.tempo_execucao\n",
    "        \n",
    "        if len(fila2) != 0:\n",
    "            prox_fim_2 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila2[0].id, FIM_DO_SERVICO_2)\n",
    "            eventos.append( prox_fim_2 )\n",
    "            \n",
    "        print(\"Saída 2\", cliente)\n",
    "\n",
    "    eventos.sort(key = lambda e: e.instante_t)\n",
    "    print(eventos)\n",
    "    print()\n",
    "#eventos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimando a fase transiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso, colocamos a lógica do simulador em uma função e modificamos para salvar as métricas ao longo do tempo e fizemos alguns plots para visualizar onde elas se estabilizam."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Acredito que o erro esteja nas linhas\n",
    "\n",
    "N1 = len(fila1)\n",
    "Nq1 = 0 if N1 == 0 else N1 - 1\n",
    "\n",
    "N2 = len(fila2)\n",
    "Nq2 = N2 if N1 > 0 or N2 == 0 else N2-1\n",
    "\n",
    "estimadores[\"N1\"].adiciona_amostra(N1, peso=tempo-tempo_anterior)\n",
    "\n",
    "estimadores[\"Nq1\"].adiciona_amostra(Nq1, peso=tempo-tempo_anterior)\n",
    "\n",
    "estimadores[\"N2\"].adiciona_amostra(N2, peso=tempo-tempo_anterior)\n",
    "\n",
    "estimadores[\"Nq2\"].adiciona_amostra(Nq2, peso=tempo-tempo_anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lamb = lambda\n",
    "#mu = mu\n",
    "#k = número de eventos de partidas tratados\n",
    "def simulador_transiente(lamb, mu, k, debug=False):\n",
    "    fila1 = []\n",
    "    fila2 = []\n",
    "\n",
    "    tempo = 0\n",
    "    tempo_anterior = 0\n",
    "\n",
    "    eventos = [ gera_chegadas(0, partial(gera_exponencial, lamb), 0) ] # começa populando com uma chegada\n",
    "    estimadores = {\n",
    "        \"W1\": Estimador(debug = debug),\n",
    "        \"W2\": Estimador(debug = debug),\n",
    "\n",
    "        \"X1\": Estimador(debug = debug),\n",
    "        \"X2\": Estimador(debug = debug),\n",
    "\n",
    "        \"N1\": Estimador(debug = debug),\n",
    "        \"N2\": Estimador(debug = debug),\n",
    "\n",
    "        \"Nq1\": Estimador(debug = debug),\n",
    "        \"Nq2\": Estimador(debug = debug)\n",
    "    }\n",
    "\n",
    "    i = 0\n",
    "    n_eventos = 0\n",
    "    while n_eventos < k: #loop de eventos, tratar k clientes\n",
    "        atual = eventos.pop(0)\n",
    "        tempo_anterior = tempo\n",
    "        tempo = atual.instante_t\n",
    "        #print(\"Tempo\", tempo, \"\\nEvento\", atual, \"\\n\")\n",
    "\n",
    "        N1 = len(fila1)\n",
    "        Nq1 = 0 if N1 == 0 else N1 - 1\n",
    "\n",
    "        N2 = len(fila2)\n",
    "        Nq2 = N2 if N1 > 0 or N2 == 0 else N2-1\n",
    "\n",
    "        estimadores[\"N1\"].adiciona_amostra(N1, peso=tempo-tempo_anterior)\n",
    "        estimadores[\"Nq1\"].adiciona_amostra(Nq1, peso=tempo-tempo_anterior)\n",
    "\n",
    "        estimadores[\"N2\"].adiciona_amostra(N2, peso=tempo-tempo_anterior)\n",
    "        estimadores[\"Nq2\"].adiciona_amostra(Nq2, peso=tempo-tempo_anterior)\n",
    "\n",
    "        if atual.tipo_evento == CHEGADA: #evento de chegada\n",
    "            fila1.append( cria_cliente(atual, cor) ) #adiciona o cliente chegado na fila\n",
    "            eventos.append(gera_chegadas(tempo, partial(gera_exponencial, lamb), i) ) #cria o próximo evento de chegada\n",
    "            #print(\"Chegada\", fila1[-1])\n",
    "\n",
    "            checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_1 for e in eventos])\n",
    "            if not checa_termino: #essa foi a primeira chegada (não tem pessoas na fila 1)\n",
    "                prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), atual.id_cliente, FIM_DO_SERVICO_1) \n",
    "                eventos.append( prox_fim_1 ) #adiciona o próximo evento de término 1\n",
    "\n",
    "                if len(fila2) != 0: # fila 2 tem alguém sendo executado\n",
    "                    prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                    prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "            i+= 1\n",
    "\n",
    "        elif atual.tipo_evento == FIM_DO_SERVICO_1:\n",
    "            cliente = fila1.pop(0) #remove o primeiro da fila 1\n",
    "            fila2.append( cliente ) #coloca cliente na fila 2\n",
    "\n",
    "            #atualiza tempos do cliente\n",
    "            cliente.tempo_execucao_1= atual.tempo_execucao\n",
    "            cliente.tempo_espera_1 = tempo - cliente.tempo_chegada - atual.tempo_execucao\n",
    "\n",
    "            checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_2 for e in eventos])\n",
    "            if not checa_termino: #essa foi o primeiro termino (não tem pessoas na fila 2)\n",
    "                eventos.append( gera_fim_servico(tempo, partial(gera_exponencial, mu), cliente.id, FIM_DO_SERVICO_2) ) #adiciona o próximo evento de término 1\n",
    "\n",
    "            if len(fila1) == 0: #se a fila 1 estiver vazia\n",
    "                pass\n",
    "            else: #se a fila 1 não estiver vazia\n",
    "                prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila1[0].id, FIM_DO_SERVICO_1)  #cria evento de término para o próximo da fila 1\n",
    "                eventos.append( prox_fim_1 ) \n",
    "\n",
    "                prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "\n",
    "            #print(\"Saída 1\", cliente)\n",
    "\n",
    "        elif atual.tipo_evento == FIM_DO_SERVICO_2:\n",
    "            cliente = fila2.pop(0)\n",
    "\n",
    "            #atualiza tempos do cliente\n",
    "            cliente.tempo_execucao_2= atual.tempo_execucao\n",
    "            cliente.tempo_espera_2 = tempo - cliente.tempo_chegada - cliente.tempo_execucao_1 - cliente.tempo_espera_1 - atual.tempo_execucao\n",
    "\n",
    "            if len(fila2) != 0:\n",
    "                prox_fim_2 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila2[0].id, FIM_DO_SERVICO_2)\n",
    "                eventos.append( prox_fim_2 )\n",
    "\n",
    "            estimadores[\"W1\"].adiciona_amostra(cliente.tempo_espera_1)\n",
    "            estimadores[\"X1\"].adiciona_amostra(cliente.tempo_execucao_1)\n",
    "\n",
    "            estimadores[\"W2\"].adiciona_amostra(cliente.tempo_espera_2)\n",
    "            estimadores[\"X2\"].adiciona_amostra(cliente.tempo_execucao_2)\n",
    "            #print(\"Saída 2\", cliente)\n",
    "            \n",
    "            n_eventos += 1 #aumenta contador de eventos de saída\n",
    "\n",
    "        eventos.sort(key = lambda e: e.instante_t)\n",
    "    return estimadores, n_eventos\n",
    "    #print(eventos)\n",
    "    #print()\n",
    "#estimadores[\"Nq2\"].t_student()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar para plotar os gráficos com diferentes seeds\n",
    "def auxiliar_transiente(seed, n_saidas):\n",
    "    random.seed(seed) #setando uma seed pra manter os testes iguais\n",
    "    lista = []\n",
    "    for r in RHOS:\n",
    "        mu = MU\n",
    "        lamb = r/2\n",
    "        start = time.time()\n",
    "        estimadores, n_eventos = simulador_transiente(lamb, mu, k=n_saidas, debug=True)\n",
    "        print(f\"Rho={r} demorou {time.time()-start:.2f} segundos\")\n",
    "        lista.append(estimadores)\n",
    "        \n",
    "    \n",
    "    #Plot dos resultados dos estimadores\n",
    "    start = time.time()\n",
    "    for i, cat in enumerate([\"W1\", \"W2\", \"X1\", \"X2\", \"N1\", \"N2\", \"Nq1\", \"Nq2\"]):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(121)\n",
    "        for estimadores in lista:\n",
    "            medias = estimadores[cat].medias\n",
    "            plt.plot(medias)\n",
    "            plt.xlabel( \"Eventos tratados\" if i > 3 else f\"Clientes atendidos\")\n",
    "        plt.legend(RHOS)\n",
    "        plt.title(f\"E[{cat}]\")\n",
    "\n",
    "        plt.subplot(122)\n",
    "        for estimadores in lista:\n",
    "            variancias = estimadores[cat].variancias\n",
    "            plt.plot(variancias)\n",
    "            plt.xlabel( \"Eventos tratados\" if i > 3 else f\"Clientes atendidos\")\n",
    "        plt.legend(RHOS)\n",
    "        plt.title(f\"V[{cat}]\")\n",
    "\n",
    "        #plt.suptitle(cat)\n",
    "        plt.show()\n",
    "    print(f\"Plots demoraram {time.time()-start:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando seed 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliar_transiente(13, 300_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando seed 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliar_transiente(42, 300_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando seed 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliar_transiente(91, 300_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feito isso, olhamos para a métrica que mais demora para estabilizar (V[W2]) para a nossa decisão. Escolhemos usar os primeiros 200000 clientes como fase transiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coleta de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabendo onde termina a fase transiente, vamos juntar tudo e adicionar a lógica de batch, onde cada simulação inicia onde a anterior termina. Escolhemos 100000 como o número de clientes por rodada e 10 rodadas por valor de rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lamb = lambda\n",
    "#mu = mu\n",
    "#n_rodadas = número de rodadas\n",
    "#partidas_rodadas = número de partidas por rodada\n",
    "def simulador(lamb, mu, n_rodadas, partidas_rodadas, debug=False):\n",
    "    fila1 = []\n",
    "    fila2 = []\n",
    "\n",
    "    tempo = 0\n",
    "    tempo_anterior = 0\n",
    "    eventos = [ gera_chegadas(0, partial(gera_exponencial, lamb), 0) ] # começa populando com uma chegada\n",
    "    \n",
    "    rodada_atual = 0\n",
    "    rodadas = []\n",
    "    for n in range(n_rodadas):\n",
    "        rodadas.append({\n",
    "        \"W1\": Estimador(), \"W2\": Estimador(),\n",
    "        \"T1\": Estimador(), \"T2\": Estimador(),\n",
    "        \"N1\": Estimador(), \"N2\": Estimador(),\n",
    "        \"Nq1\": Estimador(), \"Nq2\": Estimador()\n",
    "    })\n",
    "        \n",
    "    i = 0 #chegadas no sistema\n",
    "    rodada_atual = -1\n",
    "    while True: #loop de eventos\n",
    "        atual = eventos.pop(0)\n",
    "        tempo_anterior = tempo\n",
    "        tempo = atual.instante_t\n",
    "        \n",
    "        if rodada_atual >= 0 and rodada_atual < n_rodadas:\n",
    "            N1 = len(fila1)\n",
    "            Nq1 = 0 if N1 == 0 else N1 - 1\n",
    "            rodadas[rodada_atual][\"N1\"].adiciona_amostra(N1, peso=tempo-tempo_anterior)\n",
    "            rodadas[rodada_atual][\"Nq1\"].adiciona_amostra(Nq1, peso=tempo-tempo_anterior)\n",
    "\n",
    "            N2 = len(fila2)\n",
    "            Nq2 = N2 if N1 > 0 or N2 == 0 else N2-1\n",
    "            rodadas[rodada_atual][\"N2\"].adiciona_amostra(N2, peso=tempo-tempo_anterior)\n",
    "            rodadas[rodada_atual][\"Nq2\"].adiciona_amostra(Nq2, peso=tempo-tempo_anterior)\n",
    "\n",
    "        if atual.tipo_evento == CHEGADA: #evento de chegada\n",
    "            rodada_atual = (i-200_000)//partidas_rodadas\n",
    "            fila1.append( cria_cliente(atual, rodada_atual) ) #adiciona o cliente chegado na fila\n",
    "            eventos.append(gera_chegadas(tempo, partial(gera_exponencial, lamb), i) ) #cria o próximo evento de chegada\n",
    "            #print(\"Chegada\", fila1[-1])\n",
    "\n",
    "            checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_1 for e in eventos])\n",
    "            if not checa_termino: #essa foi a primeira chegada (não tem pessoas na fila 1)\n",
    "                prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), atual.id_cliente, FIM_DO_SERVICO_1) \n",
    "                eventos.append( prox_fim_1 ) #adiciona o próximo evento de término 1\n",
    "\n",
    "                if len(fila2) != 0: # fila 2 tem alguém sendo executado\n",
    "                    prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                    prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "            i+= 1\n",
    "\n",
    "        elif atual.tipo_evento == FIM_DO_SERVICO_1:\n",
    "            cliente = fila1.pop(0) #remove o primeiro da fila 1\n",
    "            fila2.append( cliente ) #coloca cliente na fila 2\n",
    "\n",
    "            #atualiza tempos do cliente\n",
    "            cliente.tempo_execucao_1= atual.tempo_execucao\n",
    "            cliente.tempo_espera_1 = tempo - cliente.tempo_chegada - atual.tempo_execucao\n",
    "\n",
    "            checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_2 for e in eventos])\n",
    "            if not checa_termino: #essa foi o primeiro termino (não tem pessoas na fila 2)\n",
    "                eventos.append( gera_fim_servico(tempo, partial(gera_exponencial, mu), cliente.id, FIM_DO_SERVICO_2) ) #adiciona o próximo evento de término 1\n",
    "\n",
    "            if len(fila1) == 0: #se a fila 1 estiver vazia\n",
    "                pass\n",
    "            else: #se a fila 1 não estiver vazia\n",
    "                prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila1[0].id, FIM_DO_SERVICO_1)  #cria evento de término para o próximo da fila 1\n",
    "                eventos.append( prox_fim_1 ) \n",
    "\n",
    "                prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "\n",
    "            #print(\"Saída 1\", cliente)\n",
    "\n",
    "        elif atual.tipo_evento == FIM_DO_SERVICO_2:\n",
    "            cliente = fila2.pop(0)\n",
    "\n",
    "            #atualiza tempos do cliente\n",
    "            cliente.tempo_execucao_2= atual.tempo_execucao\n",
    "            cliente.tempo_espera_2 = tempo - cliente.tempo_chegada - cliente.tempo_execucao_1 - cliente.tempo_espera_1 - atual.tempo_execucao\n",
    "\n",
    "            if len(fila2) != 0:\n",
    "                prox_fim_2 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila2[0].id, FIM_DO_SERVICO_2)\n",
    "                eventos.append( prox_fim_2 )\n",
    "            \n",
    "            #se a saída for de uma rodada além do necessário, para o loop de eventos\n",
    "            if cliente.cor >= n_rodadas: break\n",
    "            elif cliente.cor >= 0:\n",
    "                rodadas[cliente.cor][\"W1\"].adiciona_amostra(cliente.tempo_espera_1)\n",
    "                rodadas[cliente.cor][\"T1\"].adiciona_amostra(cliente.tempo_espera_1+cliente.tempo_execucao_1)\n",
    "\n",
    "                rodadas[cliente.cor][\"W2\"].adiciona_amostra(cliente.tempo_espera_2)\n",
    "                rodadas[cliente.cor][\"T2\"].adiciona_amostra(cliente.tempo_espera_2+cliente.tempo_execucao_2)\n",
    "\n",
    "        eventos.sort(key = lambda e: e.instante_t)\n",
    "    return rodadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricas = [\"W1\", \"N1\", \"Nq1\", \"T1\", \"W2\", \"N2\", \"Nq2\", \"T2\"]\n",
    "# for seed in [13, 42, 91]:\n",
    "#     print(seed)\n",
    "#     for r in RHOS:\n",
    "#         random.seed(seed)\n",
    "#         mu = MU\n",
    "#         lamb = r/2\n",
    "\n",
    "#         start = time.time()\n",
    "#         retorno = simulador(lamb, mu, N_RODADAS, N_AMOSTRAS)\n",
    "#         print(f\"Rho={r} demorou {time.time()-start:.2f} segundos\")\n",
    "\n",
    "#         arquivo = open(f\"resultados/Semente={seed}-Rho={r}.csv\", \"w\")\n",
    "#         print(\"Rodada;E[W1];V[W1];E[N1];E[Nq1];E[T1];\"\\\n",
    "#               +\"E[W2];V[W2];E[N2];E[Nq2];E[T2]\", file=arquivo)\n",
    "        \n",
    "#         metricas_gerais = {k: Estimador() for k in [\"W1\", \"N1\", \"Nq1\", \"T1\", \"W2\", \"N2\", \"Nq2\", \"T2\"]}\n",
    "#         for i, rodada in enumerate(retorno):\n",
    "#             for metrica in metricas:\n",
    "#                 metricas_gerais[metrica].adiciona_amostra(rodada[metrica].media())\n",
    "            \n",
    "#             print(i+1,rodada[\"W1\"].media(), rodada[\"W1\"].variancia(),\n",
    "#                   rodada[\"N1\"].media(),\n",
    "#                   rodada[\"Nq1\"].media(),\n",
    "#                   rodada[\"T1\"].media(),\n",
    "#                   rodada[\"W2\"].media(), rodada[\"W2\"].variancia(),\n",
    "#                   rodada[\"N2\"].media(),\n",
    "#                   rodada[\"Nq2\"].media(),\n",
    "#                   rodada[\"T2\"].media(),\n",
    "#                  sep = \";\", file=arquivo, flush=True)\n",
    "\n",
    "#         for i, tipo in enumerate([\"Superior\", \"Inferior\", \"Precisão\"]):\n",
    "#             print(tipo + \" T-student\", metricas_gerais[\"W1\"].t_student()[i], \"-\",\n",
    "#               metricas_gerais[\"N1\"].t_student()[i],\n",
    "#               metricas_gerais[\"Nq1\"].t_student()[i],\n",
    "#               metricas_gerais[\"T1\"].t_student()[i],\n",
    "#               metricas_gerais[\"W2\"].t_student()[i], \"-\",\n",
    "#               metricas_gerais[\"N2\"].t_student()[i],\n",
    "#               metricas_gerais[\"Nq2\"].t_student()[i],\n",
    "#               metricas_gerais[\"T2\"].t_student()[i],\n",
    "#              sep = \";\", file=arquivo, flush=True)\n",
    "        \n",
    "#         for i, tipo in enumerate([\"Superior\", \"Inferior\", \"Precisão\"]):\n",
    "#             print(tipo + \" Chi-Quadrado\", metricas_gerais[\"W1\"].chi_quadrado()[i], metricas_gerais[\"W1\"].variancia_chi_quadrado()[i],\n",
    "#               metricas_gerais[\"N1\"].chi_quadrado()[i],\n",
    "#               metricas_gerais[\"Nq1\"].chi_quadrado()[i],\n",
    "#               metricas_gerais[\"T1\"].chi_quadrado()[i],\n",
    "#               metricas_gerais[\"W2\"].chi_quadrado()[i], metricas_gerais[\"W2\"].variancia_chi_quadrado()[i],\n",
    "#               metricas_gerais[\"N2\"].chi_quadrado()[i],\n",
    "#               metricas_gerais[\"Nq2\"].chi_quadrado()[i],\n",
    "#               metricas_gerais[\"T2\"].chi_quadrado()[i],\n",
    "#              sep = \";\", file=arquivo, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultado = simulador(0.5, 1, 10, 10000)\n",
    "# for metrica in ['W1','W2','T1', 'T2', 'Nq1', 'Nq2']:\n",
    "#     media = resultado[0][metrica].media()\n",
    "#     print(\"Media de {}: {}\".format(metrica, media))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar o fator mínimo vamos olhar para cada fator separadamente usando rho=0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase Transiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso, vamos alterar o simulador para parar no momento em que a variancia de W2 oscile menos que 0.1% por 1000 coletas seguidas e retornar o númerdo de coletas. Para garantir a independencia de sementes, estamos executando esse teste 1000 vezes e usando o maior número de coletas necessárias para estabilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulador_transiente_otimo(lamb, mu, debug=False):\n",
    "    fila1 = []\n",
    "    fila2 = []\n",
    "\n",
    "    tempo = 0\n",
    "    tempo_anterior = 0\n",
    "\n",
    "    eventos = [ gera_chegadas(0, partial(gera_exponencial, lamb), 0) ] # começa populando com uma chegada\n",
    "    W2 = Estimador(debug = debug)\n",
    "\n",
    "    i = 0\n",
    "    n_saidas = 0\n",
    "    osciladas = 0\n",
    "    while osciladas < 10000: \n",
    "        atual = eventos.pop(0)\n",
    "        tempo_anterior = tempo\n",
    "        tempo = atual.instante_t\n",
    "\n",
    "        if atual.tipo_evento == CHEGADA: #evento de chegada\n",
    "            fila1.append( cria_cliente(atual, cor) ) #adiciona o cliente chegado na fila\n",
    "            eventos.append(gera_chegadas(tempo, partial(gera_exponencial, lamb), i) ) #cria o próximo evento de chegada\n",
    "\n",
    "            checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_1 for e in eventos])\n",
    "            if not checa_termino: #essa foi a primeira chegada (não tem pessoas na fila 1)\n",
    "                prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), atual.id_cliente, FIM_DO_SERVICO_1) \n",
    "                eventos.append( prox_fim_1 ) #adiciona o próximo evento de término 1\n",
    "\n",
    "                if len(fila2) != 0: # fila 2 tem alguém sendo executado\n",
    "                    prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                    prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "            i+= 1\n",
    "\n",
    "        elif atual.tipo_evento == FIM_DO_SERVICO_1:\n",
    "            cliente = fila1.pop(0) #remove o primeiro da fila 1\n",
    "            fila2.append( cliente ) #coloca cliente na fila 2\n",
    "\n",
    "            #atualiza tempos do cliente\n",
    "            cliente.tempo_execucao_1= atual.tempo_execucao\n",
    "            cliente.tempo_espera_1 = tempo - cliente.tempo_chegada - atual.tempo_execucao\n",
    "\n",
    "            checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_2 for e in eventos])\n",
    "            if not checa_termino: #essa foi o primeiro termino (não tem pessoas na fila 2)\n",
    "                eventos.append( gera_fim_servico(tempo, partial(gera_exponencial, mu), cliente.id, FIM_DO_SERVICO_2) ) #adiciona o próximo evento de término 1\n",
    "\n",
    "            if len(fila1) == 0: #se a fila 1 estiver vazia\n",
    "                pass\n",
    "            else: #se a fila 1 não estiver vazia\n",
    "                prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila1[0].id, FIM_DO_SERVICO_1)  #cria evento de término para o próximo da fila 1\n",
    "                eventos.append( prox_fim_1 ) \n",
    "\n",
    "                prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "\n",
    "        elif atual.tipo_evento == FIM_DO_SERVICO_2:\n",
    "            cliente = fila2.pop(0)\n",
    "\n",
    "            #atualiza tempos do cliente\n",
    "            cliente.tempo_execucao_2= atual.tempo_execucao\n",
    "            cliente.tempo_espera_2 = tempo - cliente.tempo_chegada - cliente.tempo_execucao_1 - cliente.tempo_espera_1 - atual.tempo_execucao\n",
    "\n",
    "            if len(fila2) != 0:\n",
    "                prox_fim_2 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila2[0].id, FIM_DO_SERVICO_2)\n",
    "                eventos.append( prox_fim_2 )\n",
    "            \n",
    "            v_atual = 0\n",
    "            if W2.numero_amostras > 10: v_atual = W2.variancia()\n",
    "            \n",
    "            W2.adiciona_amostra(cliente.tempo_espera_2)\n",
    "            \n",
    "            if W2.numero_amostras > 11 and abs((v_atual-W2.variancia())/v_atual) < 0.001:\n",
    "                osciladas += 1\n",
    "            else:\n",
    "                osciladas = 0\n",
    "            n_saidas += 1\n",
    "\n",
    "        eventos.sort(key = lambda e: e.instante_t)\n",
    "    return n_saidas, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes atendidos 71179\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnBUlEQVR4nO3dd3wc1b338c9Pq2YVS5Yt27JcZGNjYxs3RAdjSrAxBEIaJU9Cyg3ckEpIgSQ3lSchCUm4pDshuSRPAoQAgQsEgx2aAxjkhm3cu1wkuUuWrHqeP2a02l3JVltJO+j7fr32pdnZ2Zmf2ldH58ycMeccIiISPEl9XYCIiHSNAlxEJKAU4CIiAaUAFxEJKAW4iEhAJffmwYYMGeKKiop685AiIoG3bNmy/c65/Nj1vRrgRUVFlJSU9OYhRUQCz8x2tLVeXSgiIgGlABcRCSgFuIhIQCnARUQCSgEuIhJQCnARkYBSgIuIBFRgA/zxFaVU1zX0dRkiIn0mkAG+atdhbnt4FV97bHVflyIi0mfaDXAzSzezN8xslZmtNbPv+OvHmtlSM9tsZg+bWWrPl+tpaPJuQrHtQHVvHVJEJOF0pAVeC1zinJsOzADmmdk5wA+BnznnxgOHgE/0WJUxMlJDANSoC0VE+rF2A9x5qvynKf7DAZcAf/fXPwC8pycKbEtasld2dV1jbx1SRCThdKgP3MxCZrYSKAeeB7YAh51zzU3gUqDwBO+92cxKzKykoqIiDiV7fz0AahTgItKPdSjAnXONzrkZwEjgLGBSRw/gnFvgnCt2zhXn57eaDbFLmu/DrBa4iPRnnToLxTl3GHgBOBfINbPm6WhHArvjW9pJKwGgpl4BLiL9V0fOQsk3s1x/eQDwLmAdXpC/39/sJuCJHqqxleYWuIhIf9aRGzoUAA+YWQgv8P/mnHvKzN4GHjKzu4AVwP09WGcU5beISAcC3Dn3FjCzjfVb8frDe51a4CIiAb0S06kNLiIS0ABXfouIKMBFRIIqmAEe0YXilOYi0k8FM8AjMru2oanvChER6UOBDPBIx2o1oZWI9E+BDPDIFnjpoZq+K0REpA8FM8Aj+sCv+eW/+7ASEZG+E8wA17iliEhAA7yvCxARSQDBDHA1wUVEAhrgfV2AiEgCCGaAK8FFRIIZ4GqDi4gENMDVAhcRCWqA+x+nFg4kNTmQn4KISLcFMv3e2HYQgKy0ZOoamqjTfCgi0g8FMsB/vHADAFlpKYDmQxGR/imQAd4sO927I1yVAlxE+qFAB3h6ilf+sToFuIj0P4EO8OQkr/yq4wpwEel/Ah3gKSE/wNWFIiL9UMAD3AAFuIj0T+0GuJmNMrMXzOxtM1trZp/313/bzHab2Ur/Mb/ny43WfA54pbpQRKQfSu7ANg3A7c655WaWDSwzs+f9137mnLun58o7ufSUEABHaur7qgQR6SOrdh3mUHUdsyfkk5RkfV1On2g3wJ1ze4G9/nKlma0DCnu6sJM5s2gQb24/xNXTR/DfizZxuFoBLtLf3PbwSrbuP0ZKyCgek8d7ZxUyZ+JQ8rPT+rq0XtORFniYmRUBM4GlwPnAZ8zsI0AJXiv9UBvvuRm4GWD06NHdrReA8UOz2ba/mlF5GeRkpHCkpi4u+xWR4Kj0x74unJDPv9aX89rWA4A3xcbkgoHMnTKcCyfk9/h0G/WNTWzff4yiIZnhEyve3nOUbz25hotOzefd00cwZnBmjxy7wwFuZlnAo8AXnHNHzezXwPfwpib5HvAT4OOx73POLQAWABQXF8dpGiqH+f8x5Q5IUQtcpB9qaGziw+eM4XvvmUpTk+PtvUd5aWMFL22o4G8lpfytpJRQkpGWnMQF44fw3NtlmMF1xaO4cloB544bTHKoe+G+ft9R5t37CuBdWHjl6QXMHJ3LVx9dDcCb2w9xz3MbOb0wh29fPYUzxgzq9ucdqUMBbmYpeOH9F+fcYwDOubKI138HPBXXyk7COWju8cpOT1YfuEhAffovy9lUXskp+VmcVjCQicOzmVqYw6FjdUwcns2KnYcZNjAtqgV7oKqWQ9X1VNU2kJHmjYMlJRlTC3OYWpjDpy8ez5Hqel7cWM7ideW8uKGc59724ipnQApPrNzDQ2/uAmDC0Cxmn5rP+eMHs7m8isGZaZxZlMfwnPQ2W+57j9SwbMchXlhfwZGaehat8/Y7KCOFOROH8uSqln2fVjCQ333kDP65eh+PrdhNXmZq3L9+7Qa4mRlwP7DOOffTiPUFfv84wLXAmrhXdwLOEW6BL995uLcOKyKd5Jxj0bpyMlNDjB+WxdDsdMDrdvjQ75eGJ6bbWFbFP9fsO+F+ZozK5bLThjJvagF3/3Mdi9aVAzAwPaXN7XMyUrhmRiHXzPCG62rqGtlfVcuovAyO1zfy4oYKnli5m50Hq/nz6zu4f8m2VvuYNDyb9fsqGZGTzp4jxxk3JJOt+4+12u7CCUP4n4+dRSjJOF7fyNJtBzl4rJYLxueTn53GJ2eP4z8uHItZ/AdaO9ICPx/4MLDazFb6674G3GBmM/C6ULYDt8S9uhNwOMxvgw8fmM6+o8d769Ai/d6x2gb+6x9rOH1kDqMGZXDRxPxw3y/Ayxsr+PHCDdx0XhGPLisN902DF8TTR+bwwGs7wute+NIckpOMyuMNVFTVsujtMtKSkzhW18CrWw4wd8pwlm49wD3PbeSe5zaG33fhhCHMnTK8QzUPSA0xKi8D8M5emzd1OPOmeu+trmvg9a0HWLe3kglDs1iz+wj7j9Wx80A1UMmeI8dJDSWFw/vccYP57jVTyMlIYXBmGqGIM2DSU0JcdGp+q+P3RHhDx85CWUJLj0WkZ+JfTsdEtsBvPHs0P31+I3UNTZobXCSOtlRU8cxbe1m37yjPrPZaxyNy0jEzdh+u4bEVuwFvTqKstBT2V9VGvf9Lj6wKL3957kSq6xp4eeP+qPB+/rbZjB0SPcDXVgAC7DtynIVr97FoXRnvnjaCD545Ki6fZ0ZqMpdMGsYlk4YBcHnEH4WmJkdSkuGcw6zlY6Lo1FkoicLR8hdlUIb3L9Thmrrwv2ci0n0PLt3J72O6FvYcaflv948fPZNXt+znaE0DD5fsitruymkFXDN9BLsO1VA0OINLT/PC8ctzYdv+YxytqWf6qNxO1TM8J52bzivipvOKuvT5dEXz+eXNoZ1I4Q1BDXDX8oXMyfAGBg5X1yvAReLk6PF6nlntDXH98H2nc3phLpNHDARg54FqDlXXMX1ULhdPGgrAXddOpdQPa+c46YU1sS1u6bpgBnjETY2bW+CL1pUxJCutR0Z6RYLqjkff4qE3d3HppKGcP34IZ43NY8qIgW22JD/74ArqG5qYNSaX7z+zHoBT8jO57szo6zdGD85g9OCMqHUpoaRwMCdYI/UdLZABTkQf+CC/Bf6jZzfw4Bs7eeUrl/RhYSKJwzkXPqVt8fpyFq8vD782MD2Z7PQUiosGcfnk4Ywdksn/rtoDwLNrW84G+cWNs3q3aOmUQAa4oyXAczNaTiPadbCmbwoSSRBNTY4fLdxAQ2MT54wbDMDHzx/L1688jWfX7GPptgNsLKvk9a0HOXq8gd0ra3hi5Z7w+z9/6QTGD83i5Y0VfPWKSQzJ6j+XpQdRMAPcRZ9GGGnZjkNxv9pJpLes3XME52Di8OyoU/M66s3tB/nNS1sAwgOQ4/IzCSUZV04r4MppBYD3O1Tf6KiqbWDb/ir+vqyU8qO1zJs6nNMKBvLu6SPi90lJjwlkgENLCzw5lMSYwRnsOFANwObySgV4P/XoslKO1NTz4XPHdCn8OqupyfH1f6zmwTd2MbVwIOnJIT5zyXgmDR9IbkZKeLbMZvuraklJSiLH/6+xtqGR1FBSuD966dYDXLfgdQDyMlO5dc4pXDOjsFOTMx31p1b+r6smU9fQRMn2g1w4YUir7cyM1GQjLzmVvMw8zhiT16WvgfStQAZ47IQquRmp4QA/pHlR+q07H1tNXWMTj6/Yzc9vmElRD57tcLy+kUn/9Wz4+ZrdRwH46B/fDK9LDSVx7/UzmDtlOAbcsOB1NpVXcemkodw5fxKX/fRlAD554VhG52WE5/QxgwEpIe56eh13Pb0OgCFZqZwxZhDDBqYzcXg2syfkM3LQAF7dcoCpI3LCfxSq/fvDzpmYzyn5WcApPfY1kL4XzAB30VcWDYk48+RAzMUE0n/kZaZSXdfAzoPVzL33ZU4vzOGeD0xneE46h6vrGZ7jdbfF42KMTWVV4eXHbj2PGSNzKa+s5V/ry/na495ERnWNTdz6l+Wt3hs7oPi7V6LPtd501xUkh5LYXF7JI8tK+e1LW9lfVcfCtWWxu4py+7tODZ++l5EaOum28s4QzAAn+oT6yIGW2oamPqio9+yvqqX4rkWcO24wN503hvzsdHUZ+arrGnjvrJHcctE4vvXEWp57u4w597zYarvC3AHcd8NMZozKJZRkHKmuZ5Pf9bbrYA0HjtUyc/TJv6a1DY0A/OnjZzHL33Z4Tjo3nj2aG88ejXPOn+yonN+8tIXN5V7gv/TlOew+XMMzq/eyevdRfnnjTDaVVbGq9DAL15aROyAlPEPe+KHZ3HnFadwxbxJ7jhz3J2LaTU1dI6t3H2HFzsPsPFjN1dNH8OSqPfzk+ZbLzDPTAvmrLZ0UyO+yN4jZYnBWSwv86Dt8ZsLlO7wp11/beiA8x8SiL85m/NDsqO3e3H6QaSNzSEtO7JbY7sM13PqX5XzhsglcPHFot/ZV29BEWnISBTkDWPCRYtbsPsLjK3a3mqho9+Ea3vfrV0+6r3PG5ZGZmsw1Mwu5YPwQ0lOSyEht+XVpbiiknWD6BjMjNyOV958xkvefMTLqtTGDMznvlJZ+6ZGDMrh40lC+cNmpJ9xXYe4AAD509pio15ov9b7vhplsLq/k/iXb2FJ+7ISTPMk7SyADHIjqQ4lsgVf0QReKc44nV+2huCgv/IvWU2rqG1utm3/fEr579RT+/PoO/vof57B27xFu/N1Spo/K5R+3npdwl/9GWrHzEKt2HeZjf3yTH7z3dN43aySNTY6jx+sZNvDEV9auLj3CG9sPcs2MESxeV8aYwZnUNTZFBWrk9KJNzjEkKw3nHNV1jfzmpS38/F+b29x3Ye4AXt/qzZIX2dUB8J2rp/DB4lEc978PaSl9+wcy8orH8UOz+cF7p/VhNdLbAhngsYOYkS3wfUd6f2bC5TsP8fmHVgKw9jtzyUxL5p+r9zJhWFarlnF31dR5wfHvOy7hqVV7GJAa4ptPrOWOx7x+1+nffS687apdh7n4nhf51+1zKK+sZX9VLVMLc9o9RkVlLYMzU9u8HLqispbyyuNMGdH+fjqitt5ryQ7JSuXOx1Zzp/95xPrVh2Yxb8pwkpKMR5eVcrs/UdL3nno7aru2ug4ir841MzLTkrn98oncfvlEwPuaJocs6syV8srj/GtdORlpyfz6xS2s2+sNUn7rybV868m14e1O1AIX6Q2BDHBiBjHzI1rgWyqO9fqMYXUNLX9SpnxrIU999gI+5Q9ebfvB/JPW0vwvcEc1t/wGpIS45SLvDINBGal89sEVrbYdnJnK9gPVjPtay8SR990wk6tPco7vL1/YzI8Xbgg/v3n2OL4ydyLJoSTW7zvKtb98lZr6Rn7w3tN5z4xCNpVX8sqm/bxr8jDGDsmkscm1On2uLYer6/jMX1ewZPN+AJ74zAU8uqyUn0b040ZqHgzMy0zl4DHvFnqTCwaSkRqiZMchiscMoqq2ocPTi0Ya0MaA39DsdK4/y7uEvPnr5ZzjxQ0V3LtoI6tKjwAwIqdn/+MSOZlABrgjOqCHDow+T3bf0eMU9OIvVkNT9MDpVT9fEl7+0iNv8ZMPTg8/X7JpP8VFg0hPCXHf4k389PmNTBqezeO3nt9mkMQ67ve9pqe0tPzePX0EmWkhauub2F9VSygpievOHEWSwSU/eYltEZPQf+7BFRyuruMj5xa1uf/mlmazBS9vZcHLW1ttF9ta/vHCDSQZNDkYlTeAaSNzOasoj4+cO6bVHzDnHDO++3zUusGZqXzu0gl87tIJ4YtMmpwjNZREk3P871t7uO3hVeHwBnjm8xfinGNzeRXjh2b1+B9tM+PiSUPDEziJ9LVgBnhMC/yU/Cy+edVkUpOT+MY/1rDzQHXvBnij1wL/8tyJUa1XgEeXexeX/P6mYorueDrqtZSQ91ms31fJad98lk3/94p2L0Bp7nKIHZxsnss41gtfmsPynYe489HVnD0uj0eXlfLNJ9aSEkpiYHoKf31jB7//yJkMSA3R1OR46i1vBrp/33EJZUePs3zHofC5yM2+/e7JLN95mCdXtVyC3Rze4E1psOtgDU+/tZeH3tzFI/95LllpyXz5kVWcPjInajDwExeM5X2zRka12psvMgnvG+PamSO5duZItlZU8asXt/BRf0pRM2PCsPh2U4kERSADHKJnPDMzPn7BWF7eWAHA3c+u5/Fbz++1Whr85Lro1Hz+86JTOMXvsshKS6aqtoFF68pY7f/LHam+Mbo3/4YFr/P3T5130mPVNTYSSrKou4C0Z9boQSy8bTYAX7/yNG7587Ko1vPce1/m3HGDyU73fhySk7yzHgpzBzBr9CDmThnOfYs3kZeZypXTCpg2MpebznO8d1Zh+BTGASkh/lZSStHgDNbsOcKPF27g1GHZrN1zlKnfWhg+1iPLSsPLJd+4rNNzbYzLz+KeD0xvf0ORfiCQAe5OcG/788d7p2at2HmYN7Yd5KyxvXN5cEOj1ypuDtYt35/PN/6xhmtnFrJ4XRm/fXkr7/6F161yy+xxbCyr5IUNFeH3b7/7SmZ973lKdhxi8bqy8OT30Pqik4ZGR3InwjtWWnKI3/yfM5h/3ytsrfC6VnYerGbnwerwNt+9ZmrUe0blZfDjmNA0M+bEnPZ349len/F544dw82yvf/7Vzfu58fdLw9vMmZjPixsqyEpL1kRJIt0UzACPuCdmpMhW6Qd/+xrb776yV+qp91vgzV0ioSTjB+89HYCzxuaREkriFy94p6ydMjSLO+efBnj9zc2XTz9/22zOuGsRX3t8Nb/KSGHW6EFc88t/85bfci/5xmU0NXl9w92d5yM9JcQzn7uQLz2yirPHDeacsXncv2Qbi9eXc/4pg5l/eucHAk/kvPFD2H73lWwur2LHgWNcetowSg9Vc7z+nX3BlUhvCGaAu45NGr/rYHX4RqY9qdEfxExOajtYb7/8VDaXV3HltAKumNoSjqcVDAwvD85K46nPXsBVP1/C+379GuedMjgc3gDFdy0CID87jeRQ9wfr0lNCUXM93/2+nj1/ePzQLMYPzQK8C1dEpPsCeRLrCXpQWtlSUdX+Rl20bMdBiu54mqVbD4T7sk/UL21m/ObDZ/Du6SPCl0m3ZWphDjec5d2o9dUt3lWWN5w1ilsuGhfepqKyNtxqF5H+LZABDie+uehtEZcj74ro1423P/l31r5uwevhs1DiMYXp9689nac/dwHj8r2Z9L5+5WS+OncSxWMG8ZFzx7TzbhHpTwLbhXIin71kPLsPV/O3klK2Rpz/HG+RdzFpnn0uHl0bZsaUETks/uJFVNc1hq8sbD475avzJnGstqHbxxGR4Gu3yWhmo8zsBTN728zWmtnn/fV5Zva8mW3yP/bilHiujSFMT1KS8aP3T2dywcCoC1h6Q3fODonVfMl3rMy0ZIaeZI4QEek/OvI/fwNwu3NuMnAO8GkzmwzcASx2zk0AFvvPe0VHBjFH5Q3gxYhT9dry1Ft7KD3U+W6WsqPefCtzpwxjyVcvDq/P0hSeItKL2k0c59xeYK+/XGlm64BC4Bpgjr/ZA8CLwFd7pMrYmmg/wJsnv391y/6oqTsjfeav3vwhnT3dsPkimGU7DjFyUAaLvjgb5zjpAKWISLx1KnHMrAiYCSwFhvnhDrAPaPta7h7S1nngkT536QQAtpS3fSaKi+hIdyfrVG9D85WX+6u8eTnGD83W5dwi0us6HOBmlgU8CnzBORc145HzErDNFDSzm82sxMxKKipO3qXRUR0J3M9dMp70lCS2H2i7i6QpYhdbKjrXV57n33/wja9f2qn3iYjEU4cC3MxS8ML7L865x/zVZWZW4L9eAJS39V7n3ALnXLFzrjg/Pz8eNXeoCyU5lMSAlBD3L9lGY1PrwI9c98qmCh5fUUrl8Y6dX11T38ipw7IYmq3BRBHpOx05C8WA+4F1zrmfRrz0JHCTv3wT8ET8y2tb7GyEJ9J8h/rvP7Ou1WtNEa34vyzdyW0Pr+L0bz/Hp/7fMt7e4/2DsbGskqI7nmbN7pYrIusbm1i4toyNZT13kZCISEd0pAV+PvBh4BIzW+k/5gN3A+8ys03AZf7zXuGgQ9fSN0+udP+SbWwqq4x67ZY/Lwsvb47oJ//nmn3Mv+8VwLvdF0TP711d1/qWZiIifaHdAHfOLXHOmXNumnNuhv94xjl3wDl3qXNugnPuMufcwd4o2K+pQy3w7197enj5XT97Oeq1l/ypZyNvtxXpVy9uJiut5cawRXc8zZGa+vDMg9+5ekonqxYRia/AnvfWlZuvvLjB66Y/HnFj4Esj7q7ygYi7h//o2Q089ObOqPdP/85z4RZ4PK66FBHpjsAGeEe9/d254eWP/vFNAK5f8DqAdwefqyaH5x25c/5pzBiVG97+lU3e/Rof/OQ54XUX/ugFIL5XXYqIdEUgA7yjg5gAGanJbPvBfMC7OhNg5a7DAJwxehA5A1J47FPn8ewXLiQvM5V/fPr8Vnd8OWVoJlu/Pz9qXW/eNFlEpC3BDHA6d9d5M2Nq4UB2HaxhuT8wCfDaVm/K1tyMVCYNb5mb+/1njGT99+aFn+dlpJKUZPzwfS196rUNuiGBiPStQE7e0ZkWeLPPX3oqn/xTCY8v382s0bks33mYeVNOfOeZ9JRQq0vsrztzNB84YxT/+9YeLp8cv7vWiIh0RaBa4Ov3HaXKn0q1sz0Yl53mDVb++fUdNDqYWjiQn103o9M1JCUZ18woZEBqqP2NRUR6UGBa4PWNTcy71zs/+9xxgzv9fjPjgvFDWLJ5P8dqGyganKkQFpFAC0wLPHL6k9e2HqC8srbT+/iQf2HP5vIq0pID86mLiLQpMCnmYubK2nGCSapO5vKIPu9/rW9z6hYRkcAITIDHQ+RNh2vqdUm8iARbYPrAOzll9wlt+f58Hnh1O9edOSo+OxQR6SOBCfB4CSUZH79gbF+XISLSbYHpQolXC1xE5J0iMAEuIiLRAhPgsWehiIj0d8EJcOW3iEiU4AR4zPPIiaVERPqj4AR4TBM8PzutjyoREUkMgQnwWNbp+QhFRN5ZAhPgrbrAld8i0s8FJ8BjEjxJd8QRkX4uMAEe2wRXfItIfxeYAI89D1wNcBHp7wIT4LE0iCki/V27AW5mfzCzcjNbE7Hu22a228xW+o/5J9tHPMT2gasFLiL9XUda4P8DzGtj/c+cczP8xzPxLau12LNQKo/X9/QhRUQSWrsB7px7GTjYC7W0V0fU8yWb9/dRJSIiiaE7feCfMbO3/C6WQSfayMxuNrMSMyupqKjoxuGiZab1u6nMRUSidDXAfw2cAswA9gI/OdGGzrkFzrli51xxfn5+Fw/X0oXylXkTuWpaAbdddmqX9yUi8k7QpWasc66sednMfgc8FbeKTnhM72N2WjK/uHFWTx9ORCThdakFbmYFEU+vBdacaNt4CZ8HrtNPRESADrTAzexBYA4wxMxKgW8Bc8xsBl7Pxnbglp4r0dec3z1+IBGRYGg3wJ1zN7Sx+v4eqKVD1AAXEfEE5kpM3ZBHRCRacAI83IWiJriICAQpwP02uLpQREQ8gQnwquMNADQ0NvVxJSIiiSEwAf7fizcB8HDJrj6uREQkMQQmwJv8TvDj9WqBi4hAgAI8OckrtbFJ56OIiECgAtwbvaxXH7iICBCgAA/5Aa4WuIiIJzABnhxqboErwEVEIEABPnOUN+X4x84v6ttCREQSRGACfFBmKgCzJ3R9TnERkXeSwAR4M12JKSLiCUyAx94TU0SkvwtMgIuISDQFuIhIQAUmwNWBIiISLTAB3kyDmCIinsAEuMYwRUSiBSbAm+mOPCIingAFuJrgIiKRAhTgHvWBi4h4AhfgIiLiaTfAzewPZlZuZmsi1uWZ2fNmtsn/OKhny9QgpohIrI60wP8HmBez7g5gsXNuArDYf94r1IUiIuJpN8Cdcy8DB2NWXwM84C8/ALwnvmW1UUdPH0BEJGC62gc+zDm311/eBwyLUz3t0mmEIiKebg9iOm+awBM2kM3sZjMrMbOSioqK7h5ORER8XQ3wMjMrAPA/lp9oQ+fcAudcsXOuOD+/6zdj0CCmiEi0rgb4k8BN/vJNwBPxKad9GsQUEfF05DTCB4HXgIlmVmpmnwDuBt5lZpuAy/znPcppGFNEJEpyexs45244wUuXxrmWDlEDXETEoysxRUQCKjABrkFMEZFogQnwZhrEFBHxBCbA1QAXEYkWmABvoSa4iAgEKMCdOsFFRKIEJsCbqQ9cRMQTuAAXERGPAlxEJKACF+DqQRER8QQmwDWGKSISLTABXnqoGtD54CIizQIT4Pc8txGA9Xsr+7gSEZHEEJgAf8+MEQDMHJ3bt4WIiCSIwAT4gWN1AOQMSOnjSkREEkNgAvyVTfsBCCXpPBQREQhQgDdLCQWuZBGRHhG4NFQDXETEE7gAN02GIiICBDDARUTEE6gAz83QGSgiIs0CEeDVdQ0AXD55WB9XIiKSOAIR4N976m0A3tx+qI8rERFJHIEI8IrKWgAqjzf0cSUiIokjuTtvNrPtQCXQCDQ454rjUVSs5ot3dFs1EZEW3Qpw38XOuf1x2E+7mhTgIiJhgehCWbi2DIBjtY19XImISOLoboA74DkzW2ZmN7e1gZndbGYlZlZSUVHRrYPVNTZ16/0iIu8k3Q3wC5xzs4ArgE+b2ezYDZxzC5xzxc654vz8/G4eTkREmnUrwJ1zu/2P5cDjwFnxKEpERNrX5QA3s0wzy25eBi4H1sSrMBERObnunIUyDHjcn1wqGfirc+7ZuFQlIiLt6nKAO+e2AtPjWIuIiHRCIE4jFBGR1gIR4BdOGALApOHZfVyJiEjiCESAF4/JA+DvnzqvjysREUkcgQhwh3cJfUZKqI8rERFJHMEIcH8KFN1NTUSkRTAC3P+o+2GKiLQIRICjWQhFRFoJRIA71H0iIhIrGAHuQPktIhItGAGOU/+3iEiMYAS4WuAiIq0EI8BRH7iISKxgBLgDUxtcRCRKMAIc9aGIiMQKRIDjIEkBLiISJRAB3uSculBERGIEIsCd0yCmiEisYAQ46gIXEYkVjAB3mshKRCRWMAIcpxa4iEiMYAS4+lBERFoJRICD8ltEJFYgAtw5TWYlIhKrWwFuZvPMbIOZbTazO+JVVCzNhSIi0lqXA9zMQsAvgSuAycANZjY5XoVF0myEIiKtdacFfhaw2Tm31TlXBzwEXBOfsqJpPnARkdaSu/HeQmBXxPNS4OzYjczsZuBmgNGjR3fpQFNH5FDfoPtiiohE6vFBTOfcAudcsXOuOD8/v0v7uP6s0fzw/dPiXJmISLB1J8B3A6Mino/014mISC/oToC/CUwws7FmlgpcDzwZn7JERKQ9Xe4Dd841mNlngIVACPiDc25t3CoTEZGT6s4gJs65Z4Bn4lSLiIh0QiCuxBQRkdYU4CIiAaUAFxEJKAW4iEhAmXO9d4WjmVUAO7r49iHA/jiW05NUa/wFpU5QrT0lKLX2RJ1jnHOtroTs1QDvDjMrcc4V93UdHaFa4y8odYJq7SlBqbU361QXiohIQCnARUQCKkgBvqCvC+gE1Rp/QakTVGtPCUqtvVZnYPrARUQkWpBa4CIiEkEBLiISUIEI8N66eXLMMf9gZuVmtiZiXZ6ZPW9mm/yPg/z1Zmb3+fW9ZWazIt5zk7/9JjO7KWL9GWa22n/PfdaNe8aZ2Sgze8HM3jaztWb2+USt18zSzewNM1vl1/odf/1YM1vq7/9hf4pizCzNf77Zf70oYl93+us3mNnciPVx+3kxs5CZrTCzpxK8zu3+92elmZX46xLu++/vK9fM/m5m681snZmdm4i1mtlE/+vZ/DhqZl9IqFqdcwn9wJuqdgswDkgFVgGTe+G4s4FZwJqIdT8C7vCX7wB+6C/PB/6Jd+/lc4Cl/vo8YKv/cZC/PMh/7Q1/W/Pfe0U3ai0AZvnL2cBGvBtNJ1y9/vuz/OUUYKm/378B1/vrfwN8yl++FfiNv3w98LC/PNn/WUgDxvo/I6F4/7wAXwT+CjzlP0/UOrcDQ2LWJdz339/XA8B/+MupQG6i1hpRcwjYB4xJpFp7NATj8QDOBRZGPL8TuLOXjl1EdIBvAAr85QJgg7/8W+CG2O2AG4DfRqz/rb+uAFgfsT5quzjU/QTwrkSvF8gAluPdS3U/kBz7Pcebb/5cfznZ385ifw6at4vnzwveXaYWA5cAT/nHTbg6/fdvp3WAJ9z3H8gBtuGfQJHItcbUdznw70SrNQhdKG3dPLmwj2oZ5pzb6y/vA4b5yyeq8WTrS9tY323+v+4z8Vq2CVmv3y2xEigHnsdriR52zjW0sf9wTf7rR4DBXfgcuuJe4CtAk/98cILWCeCA58xsmXk3EofE/P6PBSqAP/pdU783s8wErTXS9cCD/nLC1BqEAE9IzvuTmVDnYJpZFvAo8AXn3NHI1xKpXudco3NuBl4L9yxgUt9W1JqZXQWUO+eW9XUtHXSBc24WcAXwaTObHfliAn3/k/G6Jn/tnJsJHMPrhghLoFoB8Mc5rgYeiX2tr2sNQoAn0s2Ty8ysAMD/WO6vP1GNJ1s/so31XWZmKXjh/Rfn3GOJXi+Ac+4w8AJed0KumTXfISpy/+Ga/NdzgANd+Bw663zgajPbDjyE143y3wlYJwDOud3+x3Lgcbw/jIn4/S8FSp1zS/3nf8cL9ESstdkVwHLnXJn/PHFq7W7fUE8/8P5ib8X716t5sGdKLx27iOg+8B8TPXjxI3/5SqIHL97w1+fh9fcN8h/bgDz/tdjBi/ndqNOAPwH3xqxPuHqBfCDXXx4AvAJchde6iRwcvNVf/jTRg4N/85enED04uBVvoCnuPy/AHFoGMROuTiATyI5YfhWYl4jff39frwAT/eVv+3UmZK3+/h4CPpaIv1c9HoLxeOCN7m7E6yv9ei8d80FgL1CP12r4BF6f5mJgE7Ao4ptgwC/9+lYDxRH7+Tiw2X9E/hAUA2v89/yCmEGdTtZ6Ad6/cW8BK/3H/ESsF5gGrPBrXQN8018/zv9h3owXkmn++nT/+Wb/9XER+/q6X88GIkbv4/3zQnSAJ1ydfk2r/Mfa5n0l4vff39cMoMT/GfgHXqglaq2ZeP9J5USsS5hadSm9iEhABaEPXERE2qAAFxEJKAW4iEhAKcBFRAJKAS4iElAKcBGRgFKAi4gE1P8Hb8LWr04alOkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(13)\n",
    "m = 0\n",
    "W2_maior = None\n",
    "for i in range(100):\n",
    "    mu = MU\n",
    "    lamb = 0.6/2\n",
    "    n_coletas, W2_novo = simulador_transiente_otimo(lamb, mu, True)\n",
    "    if n_coletas > m:\n",
    "        m = n_coletas\n",
    "        W2_maior = W2_novo\n",
    "\n",
    "print(\"Clientes atendidos\", m)\n",
    "plt.plot(W2_maior.variancias)\n",
    "plt.show()\n",
    "#plt.xlabel( \"Eventos tratados\" if i > 3 else f\"Clientes atendidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamanho da rodada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para essa estimativa, vamos usar a precisão de W2. Sendo assim, vamos modificar o simulador anterior para ignorar as 70.000 primeiras medições e, após isso, executar até a precisão chegar em 5% e retornar quantas medições foram necessárias para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulador_tamanho_rodada_otimo(lamb, mu, fase_transiente, n_rodadas,debug=False):\n",
    "    fila1 = []\n",
    "    fila2 = []\n",
    "\n",
    "    tempo = 0\n",
    "    tempo_anterior = 0\n",
    "\n",
    "    eventos = [ gera_chegadas(0, partial(gera_exponencial, lamb), 0) ] # começa populando com uma chegada\n",
    "    W2 = Estimador(debug = debug)\n",
    "    W2_maior = W2\n",
    "\n",
    "    i = 0\n",
    "    n_saidas = 0\n",
    "    n_saidas_rodada = 0\n",
    "    rodada = 0\n",
    "    while rodada < n_rodadas: \n",
    "        atual = eventos.pop(0)\n",
    "        tempo_anterior = tempo\n",
    "        tempo = atual.instante_t\n",
    "\n",
    "        if atual.tipo_evento == CHEGADA: #evento de chegada\n",
    "            fila1.append( cria_cliente(atual, cor) ) #adiciona o cliente chegado na fila\n",
    "            eventos.append(gera_chegadas(tempo, partial(gera_exponencial, lamb), i) ) #cria o próximo evento de chegada\n",
    "\n",
    "            checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_1 for e in eventos])\n",
    "            if not checa_termino: #essa foi a primeira chegada (não tem pessoas na fila 1)\n",
    "                prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), atual.id_cliente, FIM_DO_SERVICO_1) \n",
    "                eventos.append( prox_fim_1 ) #adiciona o próximo evento de término 1\n",
    "\n",
    "                if len(fila2) != 0: # fila 2 tem alguém sendo executado\n",
    "                    prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                    prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "            i+= 1\n",
    "\n",
    "        elif atual.tipo_evento == FIM_DO_SERVICO_1:\n",
    "            cliente = fila1.pop(0) #remove o primeiro da fila 1\n",
    "            fila2.append( cliente ) #coloca cliente na fila 2\n",
    "\n",
    "            #atualiza tempos do cliente\n",
    "            cliente.tempo_execucao_1= atual.tempo_execucao\n",
    "            cliente.tempo_espera_1 = tempo - cliente.tempo_chegada - atual.tempo_execucao\n",
    "\n",
    "            checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_2 for e in eventos])\n",
    "            if not checa_termino: #essa foi o primeiro termino (não tem pessoas na fila 2)\n",
    "                eventos.append( gera_fim_servico(tempo, partial(gera_exponencial, mu), cliente.id, FIM_DO_SERVICO_2) ) #adiciona o próximo evento de término 1\n",
    "\n",
    "            if len(fila1) == 0: #se a fila 1 estiver vazia\n",
    "                pass\n",
    "            else: #se a fila 1 não estiver vazia\n",
    "                prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila1[0].id, FIM_DO_SERVICO_1)  #cria evento de término para o próximo da fila 1\n",
    "                eventos.append( prox_fim_1 ) \n",
    "\n",
    "                prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "\n",
    "        elif atual.tipo_evento == FIM_DO_SERVICO_2:\n",
    "            cliente = fila2.pop(0)\n",
    "\n",
    "            #atualiza tempos do cliente\n",
    "            cliente.tempo_execucao_2= atual.tempo_execucao\n",
    "            cliente.tempo_espera_2 = tempo - cliente.tempo_chegada - cliente.tempo_execucao_1 - cliente.tempo_espera_1 - atual.tempo_execucao\n",
    "\n",
    "            if len(fila2) != 0:\n",
    "                prox_fim_2 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila2[0].id, FIM_DO_SERVICO_2)\n",
    "                eventos.append( prox_fim_2 )\n",
    "            \n",
    "            W2.adiciona_amostra(cliente.tempo_espera_2)\n",
    "            n_saidas += 1\n",
    "            \n",
    "            if n_saidas == fase_transiente: W2 = Estimador(debug = debug) #reseta métricas após fase transiente\n",
    "                \n",
    "            if W2.numero_amostras > 10 and W2.t_student()[2] < 0.05:\n",
    "                rodada += 1\n",
    "                if W2.numero_amostras > W2_maior.numero_amostras:\n",
    "                    W2_maior = W2\n",
    "                W2 = Estimador(debug = debug)\n",
    "\n",
    "        eventos.sort(key = lambda e: e.instante_t)\n",
    "    return n_saidas, W2_maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4470\n"
     ]
    }
   ],
   "source": [
    "random.seed(13)\n",
    "mu = MU\n",
    "lamb = 0.6/2\n",
    "_, W2_maior = simulador_tamanho_rodada_otimo(lamb, mu, fase_transiente=71179, n_rodadas=100, debug=False)\n",
    "print(W2_maior.numero_amostras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Número de rodadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente estamos usando a precisão T-student para a tomada de decisão. A diferença é que agora estamos olhando para a média das médias de cada rodada. Estamos executando 10 vezes usando os parametros descobertos anteriormente para escolher o melhor tamanho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulador_numero_rodadas_otimo(lamb, mu, fase_transiente, tamanho_rodada,debug=False):\n",
    "    fila1 = []\n",
    "    fila2 = []\n",
    "\n",
    "    tempo = 0\n",
    "    tempo_anterior = 0\n",
    "\n",
    "    eventos = [ gera_chegadas(0, partial(gera_exponencial, lamb), 0) ] # começa populando com uma chegada\n",
    "    W2_simulador = Estimador(debug = debug)\n",
    "    W2 = Estimador(debug = debug)\n",
    "\n",
    "    i = 0\n",
    "    n_saidas = 0\n",
    "    n_saidas_rodada = 0\n",
    "    rodada = 0\n",
    "    while rodada < 2 or W2_simulador.t_student()[2] > 0.05: \n",
    "        atual = eventos.pop(0)\n",
    "        tempo_anterior = tempo\n",
    "        tempo = atual.instante_t\n",
    "\n",
    "        if atual.tipo_evento == CHEGADA: #evento de chegada\n",
    "            fila1.append( cria_cliente(atual, cor) ) #adiciona o cliente chegado na fila\n",
    "            eventos.append(gera_chegadas(tempo, partial(gera_exponencial, lamb), i) ) #cria o próximo evento de chegada\n",
    "\n",
    "            checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_1 for e in eventos])\n",
    "            if not checa_termino: #essa foi a primeira chegada (não tem pessoas na fila 1)\n",
    "                prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), atual.id_cliente, FIM_DO_SERVICO_1) \n",
    "                eventos.append( prox_fim_1 ) #adiciona o próximo evento de término 1\n",
    "\n",
    "                if len(fila2) != 0: # fila 2 tem alguém sendo executado\n",
    "                    prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                    prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "            i+= 1\n",
    "\n",
    "        elif atual.tipo_evento == FIM_DO_SERVICO_1:\n",
    "            cliente = fila1.pop(0) #remove o primeiro da fila 1\n",
    "            fila2.append( cliente ) #coloca cliente na fila 2\n",
    "\n",
    "            #atualiza tempos do cliente\n",
    "            cliente.tempo_execucao_1= atual.tempo_execucao\n",
    "            cliente.tempo_espera_1 = tempo - cliente.tempo_chegada - atual.tempo_execucao\n",
    "\n",
    "            checa_termino = any([e.tipo_evento == FIM_DO_SERVICO_2 for e in eventos])\n",
    "            if not checa_termino: #essa foi o primeiro termino (não tem pessoas na fila 2)\n",
    "                eventos.append( gera_fim_servico(tempo, partial(gera_exponencial, mu), cliente.id, FIM_DO_SERVICO_2) ) #adiciona o próximo evento de término 1\n",
    "\n",
    "            if len(fila1) == 0: #se a fila 1 estiver vazia\n",
    "                pass\n",
    "            else: #se a fila 1 não estiver vazia\n",
    "                prox_fim_1 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila1[0].id, FIM_DO_SERVICO_1)  #cria evento de término para o próximo da fila 1\n",
    "                eventos.append( prox_fim_1 ) \n",
    "\n",
    "                prox_fim_2 = [e for e in eventos if e.tipo_evento == FIM_DO_SERVICO_2][0] #próximo término da fila 2\n",
    "                prox_fim_2.instante_t += prox_fim_1.tempo_execucao #adia o fim do próximo da fila 2 para após o fim do atual da fila 1\n",
    "\n",
    "        elif atual.tipo_evento == FIM_DO_SERVICO_2:\n",
    "            cliente = fila2.pop(0)\n",
    "\n",
    "            #atualiza tempos do cliente\n",
    "            cliente.tempo_execucao_2= atual.tempo_execucao\n",
    "            cliente.tempo_espera_2 = tempo - cliente.tempo_chegada - cliente.tempo_execucao_1 - cliente.tempo_espera_1 - atual.tempo_execucao\n",
    "\n",
    "            if len(fila2) != 0:\n",
    "                prox_fim_2 = gera_fim_servico(tempo, partial(gera_exponencial, mu), fila2[0].id, FIM_DO_SERVICO_2)\n",
    "                eventos.append( prox_fim_2 )\n",
    "            \n",
    "            W2.adiciona_amostra(cliente.tempo_espera_2)\n",
    "            n_saidas += 1\n",
    "            \n",
    "            if n_saidas == fase_transiente: W2 = Estimador(debug = debug) #reseta métricas no fim da fase transiente\n",
    "                \n",
    "            if W2.numero_amostras == tamanho_rodada:\n",
    "                rodada += 1\n",
    "                W2_simulador.adiciona_amostra(W2.media())\n",
    "                #if rodada > 2: print(W2_simulador.t_student()[2])\n",
    "                W2 = Estimador(debug = debug)\n",
    "\n",
    "        eventos.sort(key = lambda e: e.instante_t)\n",
    "    return n_saidas, W2_simulador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(13)\n",
    "m = 0\n",
    "for i in range(5):\n",
    "    mu = MU\n",
    "    lamb = 0.6/2\n",
    "    _, W2 = simulador_numero_rodadas_otimo(lamb, mu, fase_transiente=71179, tamanho_rodada=3765, debug=False)\n",
    "    if m < W2.numero_amostras: m = W2.numero_amostras\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimando para diferentes valores de rho"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comentei a célula abaixo pois ela demorou mais de 1 hora para rodar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in RHOS:\n",
    "#     print(\"RHO =\", r)\n",
    "#     mu = MU\n",
    "#     lamb = r/2\n",
    "    \n",
    "#     #tamanho fase transiente\n",
    "#     random.seed(13)\n",
    "#     transiente_otima = 0\n",
    "#     for i in range(100):\n",
    "#         n_coletas, _ = simulador_transiente_otimo(lamb, mu)\n",
    "#         if n_coletas > transiente_otima:\n",
    "#             transiente_otima = n_coletas\n",
    "#     print(\"Tamanho da Fase Transiente:\", transiente_otima)\n",
    "    \n",
    "#     #tamanho da rodada\n",
    "#     random.seed(13)\n",
    "#     _, W2 = simulador_tamanho_rodada_otimo(lamb, mu, fase_transiente=transiente_otima, n_rodadas=100, debug=False)\n",
    "#     tamanho_rodada = W2.numero_amostras\n",
    "#     print(\"Tamanho da Rodada:\", tamanho_rodada)\n",
    "    \n",
    "#     #número de rodadas\n",
    "#     random.seed(13)\n",
    "#     numero_rodadas = 0\n",
    "#     for i in range(5):\n",
    "#         _, W2 = simulador_numero_rodadas_otimo(lamb, mu, fase_transiente=transiente_otima, tamanho_rodada=tamanho_rodada, debug=False)\n",
    "#         if numero_rodadas < W2.numero_amostras: numero_rodadas = W2.numero_amostras\n",
    "#     print(\"Número de rodadas:\", numero_rodadas)\n",
    "    \n",
    "#     print(f\"Fator para RHO {r} = {transiente_otima} + {tamanho_rodada}*{numero_rodadas} = {transiente_otima + tamanho_rodada*numero_rodadas}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
